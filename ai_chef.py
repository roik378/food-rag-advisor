import os
import google.generativeai as genai
from search_engine import search_food  # å¼•å…¥æˆ‘ä»¬åˆšæ‰å†™å¥½çš„æœç´¢æ¨¡å—

# ==========================================
# 1. é…ç½®åŒºåŸŸ (Configuration)
# ==========================================

# ğŸ”‘ å¦‚æœä½ æœ‰ Gemini API Keyï¼Œè¯·åœ¨è¿™é‡Œå¡«å…¥
# å¦‚æœæ²¡æœ‰ï¼Œä¿æŒä¸ºç©ºï¼Œä»£ç ä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°â€œæ¨¡æ‹Ÿæ¨¡å¼â€
GOOGLE_API_KEY = ""  

# ğŸŒ å¦‚æœä½ åœ¨å›½å†…ä¸”æœ‰ VPNï¼Œå¯èƒ½éœ€è¦é…ç½®ä»£ç† (ä¾‹å¦‚ http://127.0.0.1:7890)
# os.environ["HTTP_PROXY"] = "http://127.0.0.1:7890"
# os.environ["HTTPS_PROXY"] = "http://127.0.0.1:7890"

if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-pro')
    print("âœ¨ å·²é…ç½® Google Gemini API")
else:
    model = None
    print("âš ï¸ æœªæ£€æµ‹åˆ° API Keyï¼Œå°†ä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿæ¨¡å¼ (Mock Mode)")


# ==========================================
# 2. æ ¸å¿ƒé€»è¾‘ï¼šæ„é€  Prompt å¹¶è·å–å›ç­”
# ==========================================

def get_smart_advice(user_query):
    """
    RAG çš„æ ¸å¿ƒæµç¨‹ï¼šæ£€ç´¢ (Retrieval) -> å¢å¼º (Augmented) -> ç”Ÿæˆ (Generation)
    """
    
    # --- A. æ£€ç´¢ (Retrieval) ---
    print(f"\nğŸ¤– æ€è€ƒä¸­: æ­£åœ¨å»æ•°æ®åº“æŸ¥è¯¢ '{user_query}'...")
    # è°ƒç”¨æˆ‘ä»¬ä¹‹å‰çš„æœç´¢å‡½æ•°ï¼Œæ‹¿å‰ 3 å
    restaurants = search_food(user_query, top_k=3)
    
    if not restaurants:
        return "æŠ±æ­‰ï¼ŒåŸæœ¬çš„æ•°æ®åº“é‡Œå¥½åƒæ‰¾ä¸åˆ°åˆé€‚çš„é¤å…ã€‚"

    # --- B. å¢å¼º (Augmented) - æ„å»ºä¸Šä¸‹æ–‡ ---
    # æˆ‘ä»¬è¦æŠŠç»“æ„åŒ–çš„æ•°æ®ï¼Œå˜æˆä¸€æ®µè¯ï¼Œå–‚ç»™ AI
    context_text = ""
    for i, r in enumerate(restaurants, 1):
        context_text += f"{i}. {r['name']} ({r['category']}): ç‰¹è‰²æ˜¯{r['features']}ã€‚æè¿°ï¼š{r['description']}ã€‚ä»·æ ¼ï¼š{r['price']}å…ƒã€‚\n"

    # æ„å»ºæœ€ç»ˆçš„æç¤ºè¯ (Prompt Engineering)
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¿åŠ¨è¥å…»å¸ˆå’Œç¾é£Ÿå®¶ã€‚
    
    ç”¨æˆ·ç°åœ¨çš„éœ€æ±‚æ˜¯ï¼š"{user_query}"
    
    è¿™æ˜¯æˆ‘ä»¬æ•°æ®åº“é‡Œæ£€ç´¢åˆ°çš„æœ€åŒ¹é…çš„å‡ å®¶é¤å…ï¼š
    {context_text}
    
    è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚å’Œä¸Šé¢çš„é¤å…ä¿¡æ¯ï¼Œæ¨è 1 å®¶æœ€åˆé€‚çš„é¤å…ï¼Œå¹¶è§£é‡Šä¸ºä»€ä¹ˆã€‚
    è¯­æ°”è¦è½»æ¾ã€é¼“åŠ±ï¼Œåƒæœ‹å‹ä¸€æ ·ã€‚å¦‚æœç”¨æˆ·åˆšè¿åŠ¨å®Œï¼Œè®°å¾—æé†’è¡¥å……æ°´åˆ†æˆ–è›‹ç™½è´¨ã€‚
    """

    # --- C. ç”Ÿæˆ (Generation) ---
    print("ğŸ“ æ­£åœ¨ç»„ç»‡è¯­è¨€ç”Ÿæˆå»ºè®®...")
    
    # å°è¯•è°ƒç”¨çœŸå® AI
    if model:
        try:
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            print(f"âŒ API è°ƒç”¨å¤±è´¥ (å¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜): {e}")
            print("ğŸ”„ åˆ‡æ¢å›æœ¬åœ°æ¨¡æ‹Ÿæ¨¡å¼...")
    
    # --- D. å…œåº•æ–¹æ¡ˆ (Mock Mode) ---
    # å¦‚æœæ²¡æœ‰ APIï¼Œæˆ‘ä»¬å°±ç”¨ Python ç®€å•æ‹¼å‡‘ä¸€ä¸ªå›ç­”ï¼Œå‡è£…æ˜¯ AI
    best_match = restaurants[0]
    mock_response = (
        f"\n[æœ¬åœ°æ¨¡æ‹ŸAIå›å¤]ï¼š\n"
        f"å˜¿ï¼æ ¹æ®ä½ çš„éœ€æ±‚ï¼Œæˆ‘å¼ºçƒˆæ¨èä½ è¯•è¯• **{best_match['name']}**ï¼\n"
        f"è¿™å°±ä½äºç¦ç”°åŒºï¼Œåªè¦ {best_match['price']} å…ƒã€‚\n"
        f"æ—¢ç„¶ä½ æƒ³è¦â€œ{user_query}â€ï¼Œè¿™å®¶åº—çš„ **{best_match['features']}** ç‰¹è‰²ç®€ç›´å¤ªé€‚åˆä½ äº†ã€‚\n"
        f"ğŸ’¡ å°è´´å£«ï¼š{best_match['description']}"
    )
    return mock_response


# ==========================================
# 3. ä¸»ç¨‹åºäº¤äº’
# ==========================================
if __name__ == "__main__":
    print("="*50)
    print("ğŸ¥— ç¦ç”° AI é¥®é£Ÿé¡¾é—®å·²ä¸Šçº¿ (è¾“å…¥ 'q' é€€å‡º)")
    print("="*50)

    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("\nğŸ‘‡ è¯·è¾“å…¥ä½ çš„éœ€æ±‚ (ä¾‹å¦‚: ç»ƒå®Œè…¿æƒ³åƒè‚‰): ")
        
        if user_input.lower() in ['q', 'quit', 'exit']:
            print("ğŸ‘‹ä»¥æ­¤è‡´æ•¬ä½ çš„å¥åº·ç”Ÿæ´»ï¼Œæ‹œæ‹œï¼")
            break
        
        if not user_input.strip():
            continue

        # è·å– AI å»ºè®®
        advice = get_smart_advice(user_input)
        
        # æ‰“å°ç»“æœ
        print("\nğŸ’¬ AI å»ºè®®:")
        print("-" * 40)
        print(advice)
        print("-" * 40)